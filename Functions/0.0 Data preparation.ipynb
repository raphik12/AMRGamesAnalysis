{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n",
    "Imports libraries\n",
    "\n",
    "Loads data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "print(\"0.0 data preparation\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.transforms as tr\n",
    "import seaborn as sns\n",
    "import re\n",
    "import json\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "\n",
    "from random import randint\n",
    "from ipywidgets import FloatProgress,IntProgress,IntText,Text,interact,interactive,IntSlider,FloatSlider\n",
    "from IPython.display import display\n",
    "from itertools import chain\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### common variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions & columns\n",
    "indexColumn = 'index'\n",
    "emailQuestion = 'Email'\n",
    "timestampQuestion = 'Timestamp'\n",
    "idQuestion = 'ID'\n",
    "nameQuestion = 'Name'\n",
    "gameQuestion = 'Which game have you just played?'\n",
    "remarksQuestion = '12. Write here your remarks about the game: which feature was missing, what failed or glitched, what was great:'\n",
    "questionCount = 12\n",
    "firstLikertQuestionIndex = 0\n",
    "lastLikertQuestionIndex = 11\n",
    "firstSUSQuestionIndex = 0\n",
    "lastSUSQuestionIndex = 10\n",
    "questionArrayInt = [i+1 for i in range(questionCount)]\n",
    "questionArrayStr = sorted([\"Q\" + \"{0:0=2d}\".format(i) for i in questionArrayInt])\n",
    "#questionArrayStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryCreateFolder(path, displayMessage = False):\n",
    "    try:  \n",
    "        os.mkdir(path)\n",
    "    except OSError:  \n",
    "        if displayMessage:\n",
    "            print (\"Creation of the directory %s failed\" % path)\n",
    "    else:  \n",
    "        if displayMessage:\n",
    "            print (\"Successfully created the directory %s \" % path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the name of the directory to be created\n",
    "graphsSavePathStem = \"../Graphs\"\n",
    "tryCreateFolder(graphsSavePathStem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixSUSNormalized = \"SUSNormalized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolderPath = \"../Data/\"\n",
    "unanonymizedDataFolderPath = dataFolderPath + \"UnanonymizedData/\"\n",
    "csvSuffix = '.csv'\n",
    "rawSuffix = \"_event_raw\"\n",
    "rawAnonymizedSuffix = \"_event_raw_unanonymized\"\n",
    "dataStem = \"_data\"\n",
    "SUSNormalizedSuffix = \"_SUSNormalized\"\n",
    "\n",
    "# Miranda House data\n",
    "dateStemMirandaHouse                       = \"2019-06-03\"\n",
    "unanonymizedDataFilesNamesStemMirandaHouse = dateStemMirandaHouse + rawAnonymizedSuffix\n",
    "dataFilesNamesStemMirandaHouse             = dateStemMirandaHouse + rawSuffix\n",
    "unanonymizedRaw20190603PathMirandaHouse    = unanonymizedDataFolderPath + unanonymizedDataFilesNamesStemMirandaHouse           + csvSuffix\n",
    "raw20190603PathMirandaHouse                = dataFolderPath             + dataFilesNamesStemMirandaHouse                       + csvSuffix\n",
    "data20190603Path                           = dataFolderPath             + dateStemMirandaHouse + dataStem                      + csvSuffix\n",
    "data20190603SUSNormalizedPath              = dataFolderPath             + dateStemMirandaHouse + dataStem + SUSNormalizedSuffix + csvSuffix\n",
    "\n",
    "# Cit√© des Sciences data\n",
    "dateStemCiteDesSciences                       = \"2019-07-03\"\n",
    "unanonymizedDataFilesNamesStemCiteDesSciences = dateStemCiteDesSciences + rawAnonymizedSuffix\n",
    "dataFilesNamesStemCiteDesSciences             = dateStemCiteDesSciences + rawSuffix\n",
    "unanonymizedRaw20190703PathCiteDesSciences    = unanonymizedDataFolderPath + unanonymizedDataFilesNamesStemCiteDesSciences + csvSuffix\n",
    "raw20190703PathCiteDesSciences                = dataFolderPath             + dataFilesNamesStemCiteDesSciences             + csvSuffix\n",
    "data20190703Path                              = dataFolderPath             + dateStemCiteDesSciences + dataStem            + csvSuffix\n",
    "data20190703SUSNormalizedPath                 = dataFolderPath             + dateStemCiteDesSciences + dataStem + SUSNormalizedSuffix + csvSuffix\n",
    "\n",
    "# Kigali data\n",
    "dateStemKigali                       = \"2019-08-28\"\n",
    "unanonymizedDataFilesNamesStemKigali = dateStemKigali + rawAnonymizedSuffix\n",
    "dataFilesNamesStemKigali             = dateStemKigali + rawSuffix\n",
    "unanonymizedRaw20190828PathKigali    = unanonymizedDataFolderPath + unanonymizedDataFilesNamesStemKigali + csvSuffix\n",
    "raw20190828PathKigali                = dataFolderPath             + dataFilesNamesStemKigali             + csvSuffix\n",
    "data20190828Path                     = dataFolderPath             + dateStemKigali + dataStem            + csvSuffix\n",
    "data20190828SUSNormalizedPath        = dataFolderPath             + dateStemKigali + dataStem + SUSNormalizedSuffix + csvSuffix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data anonymization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: works in-place\n",
    "def fixData(dataToFix):\n",
    "    questionsInvolved = [gameQuestion]\n",
    "    wrongSpelling = \"Fungal Invasion\"\n",
    "    correctSpelling = \"Fungal Invaders\"\n",
    "    for answer in dataToFix.index:\n",
    "        for question in questionsInvolved:\n",
    "            if dataToFix.loc[answer, question] == wrongSpelling:\n",
    "                dataToFix.loc[answer, question] = correctSpelling\n",
    "    return dataToFix\n",
    "        \n",
    "\n",
    "#testData = raw20190603.copy()\n",
    "#fixData(testData)\n",
    "#testData.loc[:, questionsInvolved]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixRawData(rawPath):\n",
    "    raw = pd.read_csv(rawPath, index_col=indexColumn, dtype=str)\n",
    "    fixData(raw)\n",
    "    raw.to_csv(rawPath, encoding='utf-8')\n",
    "    \n",
    "#fixRawData(raw20190603PathMirandaHouse)\n",
    "#fixRawData(raw20190703PathCiteDesSciences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns anonymized data: replaces Name by identifier and removes the Email column\n",
    "# reads from the unanomizedresult to the anonymizedPath\n",
    "def preprocessAnonymize(unanonymizedPath, anonymizedPath):\n",
    "    \n",
    "    # TODO filter out tests by our team members and organizers\n",
    "    \n",
    "    unanonymizedData = pd.read_csv(unanonymizedPath,dtype=str)\n",
    "\n",
    "    unanonymizedData = unanonymizedData.drop(axis=1, columns=[emailQuestion])\n",
    "\n",
    "    nameSet = set(unanonymizedData[nameQuestion])\n",
    "    nameSeries = pd.Series(list(nameSet))\n",
    "    for answerIndex in unanonymizedData.index:\n",
    "        name = unanonymizedData.loc[answerIndex, nameQuestion]\n",
    "        unanonymizedData.loc[answerIndex, nameQuestion] = nameSeries.index[nameSeries == name][0]\n",
    "    unanonymizedData.rename(columns={nameQuestion:idQuestion}, inplace=True)\n",
    "\n",
    "    fixData(unanonymizedData)\n",
    "        \n",
    "    if indexColumn in unanonymizedData.columns:\n",
    "        unanonymizedData = unanonymizedData.set_index(indexColumn)\n",
    "        \n",
    "    print(\"writing to \" + anonymizedPath)\n",
    "    unanonymizedData.to_csv(anonymizedPath, encoding='utf-8')\n",
    "    \n",
    "    return unanonymizedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python adds an artefact index column with indices 0,..,n _by default_ when reading then writing a csv without using the argument index_col=.\n",
    "# This function fixes the consequences of forgetting to use this argument.\n",
    "def getRidOfArtefactFirstColumn(rawPath):\n",
    "    raw = pd.read_csv(rawPath,dtype=str)\n",
    "    raw = raw.drop(axis=1, columns=raw.columns[0])\n",
    "    raw = raw.set_index('Timestamp')\n",
    "    raw.to_csv(rawPath, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doAnonymize = False\n",
    "\n",
    "if doAnonymize:\n",
    "    raw20190603 = preprocessAnonymize(\\\n",
    "        unanonymizedRaw20190603PathMirandaHouse,\\\n",
    "        raw20190603PathMirandaHouse)\n",
    "    \n",
    "if doAnonymize:\n",
    "    raw20190703 = preprocessAnonymize(\\\n",
    "        unanonymizedRaw20190703PathCiteDesSciences,\\\n",
    "        raw20190703PathCiteDesSciences)\n",
    "\n",
    "if doAnonymize:\n",
    "    # first merge the three separate data files\n",
    "    unanonymizedPath1 = \"../Data/UnanonymizedData/2019-08-28_website_Game-Questionnaire-Game1.csv\"\n",
    "    unanonymizedPath2 = \"../Data/UnanonymizedData/2019-08-28_website_Game-Questionnaire-Game2.csv\"\n",
    "    unanonymizedPath3 = \"../Data/UnanonymizedData/2019-08-28_website_Game-Questionnaire-Game3.csv\"\n",
    "\n",
    "    unanonymized1 = pd.read_csv(unanonymizedPath1,dtype=str)\n",
    "    unanonymized2 = pd.read_csv(unanonymizedPath2,dtype=str)\n",
    "    unanonymized3 = pd.read_csv(unanonymizedPath3,dtype=str)\n",
    "\n",
    "    concatenated = pd.concat([unanonymized1, unanonymized2, unanonymized3])\n",
    "\n",
    "    assert len(unanonymized1) + len(unanonymized2) + len(unanonymized3) == len(concatenated)\n",
    "\n",
    "    concatenated.index = range(len(concatenated.index))\n",
    "    concatenated.index.name = indexColumn\n",
    "    concatenated.to_csv(unanonymizedRaw20190828PathKigali, encoding='utf-8')\n",
    "    \n",
    "    raw20190828 = preprocessAnonymize(\\\n",
    "        unanonymizedRaw20190828PathKigali,\\\n",
    "        raw20190828PathKigali)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miranda House\n",
    "try:\n",
    "    raw20190603  = pd.read_csv(raw20190603PathMirandaHouse, index_col=indexColumn, dtype=str)\n",
    "except:\n",
    "    print(\"Miranda House data read failed: processing raw data...\")\n",
    "    raw20190603 = preprocessAnonymize(unanonymizedRaw20190603PathMirandaHouse, raw20190603PathMirandaHouse)\n",
    "    raw20190603 = pd.read_csv(raw20190603PathMirandaHouse, index_col=indexColumn, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cite des Sciences\n",
    "try:\n",
    "    raw20190703  = pd.read_csv(raw20190703PathCiteDesSciences, index_col=indexColumn, dtype=str)\n",
    "except:\n",
    "    print(\"Cite des Sciences data read failed: processing raw data...\")\n",
    "    raw20190703 = preprocessAnonymize(unanonymizedRaw20190703PathCiteDesSciences, raw20190703PathCiteDesSciences)\n",
    "    raw20190703 = pd.read_csv(raw20190703PathCiteDesSciences, index_col=indexColumn, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kigali\n",
    "try:\n",
    "    raw20190828  = pd.read_csv(raw20190828PathKigali, index_col=indexColumn, dtype=str)\n",
    "except:\n",
    "    print(\"Kigali data read failed: processing raw data...\")\n",
    "    raw20190828 = preprocessAnonymize(unanonymizedRaw20190828PathKigali, raw20190828PathKigali)\n",
    "    raw20190828 = pd.read_csv(raw20190828PathKigali, index_col=indexColumn, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert ((raw20190603.columns == raw20190703.columns).all()), \\\n",
    "(\"column mismatch: data from different experiments must have the same columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## additional treatment: column name extraction\n",
    "Game question\n",
    "short, indexed, Likert, SUS questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstQuestionIndex = len(raw20190603.columns)-len(questionArrayStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortQuestions = pd.Series(index=questionArrayStr, data=raw20190603.columns[firstQuestionIndex:])\n",
    "shortQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexedQuestions = pd.Series(index=range(1,13), data=raw20190603.columns[firstQuestionIndex:])\n",
    "indexedQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexedLikertQuestions = indexedQuestions[firstLikertQuestionIndex:lastLikertQuestionIndex]\n",
    "indexedLikertQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveLikertQuestions = indexedLikertQuestions.copy()\n",
    "positiveLikertQuestions = positiveLikertQuestions[positiveLikertQuestions.index % 2 == 1]\n",
    "positiveLikertQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negativeLikertQuestions = indexedLikertQuestions.copy()\n",
    "negativeLikertQuestions = negativeLikertQuestions[negativeLikertQuestions.index % 2 == 0]\n",
    "negativeLikertQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortLikertQuestions = shortQuestions[firstLikertQuestionIndex:lastLikertQuestionIndex]\n",
    "shortLikertQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexedSUSQuestions = indexedQuestions[firstSUSQuestionIndex:lastSUSQuestionIndex]\n",
    "indexedSUSQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveSUSQuestions = indexedSUSQuestions.copy()\n",
    "positiveSUSQuestions = positiveSUSQuestions[positiveSUSQuestions.index % 2 == 1]\n",
    "positiveSUSQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negativeSUSQuestions = indexedSUSQuestions.copy()\n",
    "negativeSUSQuestions = negativeSUSQuestions[negativeSUSQuestions.index % 2 == 0]\n",
    "negativeSUSQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shortSUSQuestions = shortQuestions[firstSUSQuestionIndex:lastSUSQuestionIndex]\n",
    "shortSUSQuestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-word question descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortDescQuestions = pd.Series(index=raw20190603.columns[firstQuestionIndex:], data=[\n",
    "     \"frequency\",\t\t\t\t#01. I think that I would like to play this game frequently.',\n",
    "     \"complexity\",\t\t\t\t#02. I found the game unnecessarily complex.',\n",
    "     \"ease\",\t\t\t\t\t#03. I thought the game was easy to play.',\n",
    "     \"need for support\",\t\t#04. I think that I would need the support of a technical person to be able to play this game.',    \n",
    "     \"integration\",\t\t\t\t#05. I found the various functions in this game were well integrated.',\n",
    "     \"consistency\",\t\t\t\t#06. I thought there was too much inconsistency in this game.',\n",
    "     \"others' learning\",\t\t#07. I would imagine that most people would learn to play this game very quickly.',\n",
    "     \"convenience\",\t\t\t\t#08. I found the game very cumbersome to play.',\n",
    "\t \"confidence\",\t\t\t\t#09. I felt very confident using the game.',\n",
    "\t \"my learning\",\t\t\t\t#10. I needed to learn a lot of things before I could get going with this game.',\n",
    "\t \"recommendation\",\t\t\t#11. I would recommend this game to a friend.',\n",
    "\t \"remarks\",\t\t\t\t\t#12. Write here your remarks about the game: which feature was missing, what failed or glitched, what was great:',\n",
    "\t ])\n",
    "shortDescQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortDescQuestions = pd.Series(index=raw20190603.columns[firstQuestionIndex:], data=[\n",
    "     \"replay appeal\",\t\t\t#01. I think that I would like to play this game frequently.',\n",
    "     \"simplicity\",\t\t\t\t#02. I found the game unnecessarily complex.',\n",
    "     \"ease\",\t\t\t\t\t#03. I thought the game was easy to play.',\n",
    "     \"autonomy\",\t\t        #04. I think that I would need the support of a technical person to be able to play this game.',    \n",
    "     \"integration\",\t\t\t\t#05. I found the various functions in this game were well integrated.',\n",
    "     \"consistency\",\t\t\t\t#06. I thought there was too much inconsistency in this game.',\n",
    "     \"learnable by others\",\t\t#07. I would imagine that most people would learn to play this game very quickly.',\n",
    "     \"convenience\",\t\t\t\t#08. I found the game very cumbersome to play.', maniability\n",
    "\t \"confidence\",\t\t\t\t#09. I felt very confident using the game.',\n",
    "\t \"learnable by self\",\t    #10. I needed to learn a lot of things before I could get going with this game.',\n",
    "\t \"recommendation\",\t\t\t#11. I would recommend this game to a friend.',\n",
    "\t \"remarks\",\t\t\t\t\t#12. Write here your remarks about the game: which feature was missing, what failed or glitched, what was great:',\n",
    "\t ])\n",
    "shortDescQuestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## game names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = raw20190603[gameQuestion].unique()\n",
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameDrBugTitle = 'Dr Bug: Microbe Mayhem'\n",
    "gameSuperbugsTitle = 'Superbugs: the Game'\n",
    "gameFungalTitle = 'Fungal Invaders'\n",
    "\n",
    "assert (set(games)==set((gameDrBugTitle, gameSuperbugsTitle, gameFungalTitle))), (\"Wrong list of games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identityGameNames = pd.Series(index=[gameDrBugTitle, gameSuperbugsTitle, gameFungalTitle],\n",
    "                           data=[gameDrBugTitle, gameSuperbugsTitle, gameFungalTitle])\n",
    "shortGameNames = pd.Series(index=identityGameNames.index,\n",
    "                           data=['Dr Bug', 'Superbugs', 'Fungal Invaders'])\n",
    "shortGameNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getShortGameTitle(longGameName):\n",
    "    return shortGameNames.get(longGameName, \"unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## advanced treatment: data refinement\n",
    "Scores are stored as strings and must be converted to integers and NaNs for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumericalData(anonymizedData):\n",
    "    numericalData = anonymizedData.copy()\n",
    "\n",
    "    for question in indexedLikertQuestions:\n",
    "        for respondent in numericalData.index:\n",
    "            try:\n",
    "                numericalData.loc[respondent, question] = int(numericalData.loc[respondent, question])\n",
    "            except:\n",
    "                numericalData.loc[respondent, question] = np.nan\n",
    "    return numericalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormalizedNumericalData(numericalData):\n",
    "    # transforms the agreement scores (1-5 Likert scale) into a 0-4 mark with 0 = bad and 4 = great\n",
    "    normalizedNumericalData = numericalData.copy()\n",
    "    for respondent in normalizedNumericalData.index:\n",
    "        for question in indexedLikertQuestions:\n",
    "            answer = normalizedNumericalData.loc[respondent, question]\n",
    "            if pd.notna(answer):\n",
    "                if question in negativeLikertQuestions.values:            \n",
    "                    normalizedNumericalData.loc[respondent, question] = 5-answer\n",
    "                else:\n",
    "                    normalizedNumericalData.loc[respondent, question] = answer-1\n",
    "                    \n",
    "    return normalizedNumericalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miranda House data\n",
    "\n",
    "try:\n",
    "    data20190603               = pd.read_csv(data20190603Path, index_col=indexColumn, dtype=str)\n",
    "    data20190603SUSNormalized  = pd.read_csv(data20190603SUSNormalizedPath, index_col=indexColumn, dtype=str)\n",
    "except:\n",
    "    print(\"data20190603 read failed: processing raw data...\")\n",
    "    data20190603 = getNumericalData(raw20190603)\n",
    "    data20190603SUSNormalized = getNormalizedNumericalData(data20190603)\n",
    "    \n",
    "    data20190603.to_csv(data20190603Path, encoding='utf-8')\n",
    "    data20190603SUSNormalized.to_csv(data20190603SUSNormalizedPath, encoding='utf-8')\n",
    "    \n",
    "    data20190603               = pd.read_csv(data20190603Path, index_col=indexColumn, dtype=str)\n",
    "    data20190603SUSNormalized  = pd.read_csv(data20190603SUSNormalizedPath, index_col=indexColumn, dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cite des Sciences data\n",
    "\n",
    "try:\n",
    "    data20190703               = pd.read_csv(data20190703Path, index_col=indexColumn, dtype=str)\n",
    "    data20190703SUSNormalized  = pd.read_csv(data20190703SUSNormalizedPath, index_col=indexColumn, dtype=str)\n",
    "except:\n",
    "    print(\"data20190703 read failed: processing raw data...\")\n",
    "    data20190703 = getNumericalData(raw20190703)\n",
    "    data20190703SUSNormalized = getNormalizedNumericalData(data20190703)\n",
    "    \n",
    "    data20190703.to_csv(data20190703Path, encoding='utf-8')\n",
    "    data20190703SUSNormalized.to_csv(data20190703SUSNormalizedPath, encoding='utf-8')\n",
    "    \n",
    "    data20190703               = pd.read_csv(data20190703Path, index_col=indexColumn, dtype=str)\n",
    "    data20190703SUSNormalized  = pd.read_csv(data20190703SUSNormalizedPath, index_col=indexColumn, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kigali data\n",
    "\n",
    "try:\n",
    "    data20190828               = pd.read_csv(data20190828Path, index_col=indexColumn, dtype=str)\n",
    "    data20190828SUSNormalized  = pd.read_csv(data20190828SUSNormalizedPath, index_col=indexColumn, dtype=str)\n",
    "except:\n",
    "    print(\"data20190828 read failed: processing raw data...\")\n",
    "    data20190828 = getNumericalData(raw20190828)\n",
    "    data20190828SUSNormalized = getNormalizedNumericalData(data20190828)\n",
    "    \n",
    "    data20190828.to_csv(data20190828Path, encoding='utf-8')\n",
    "    data20190828SUSNormalized.to_csv(data20190828SUSNormalizedPath, encoding='utf-8')\n",
    "    \n",
    "    data20190828               = pd.read_csv(data20190828Path, index_col=indexColumn, dtype=str)\n",
    "    data20190828SUSNormalized  = pd.read_csv(data20190828SUSNormalizedPath, index_col=indexColumn, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dict()\n",
    "\n",
    "datasets[\"data20190603\"] = data20190603\n",
    "datasets[\"data20190603SUSNormalized\"] = data20190603SUSNormalized\n",
    "datasets[\"data20190703\"] = data20190703\n",
    "datasets[\"data20190703SUSNormalized\"] = data20190703SUSNormalized\n",
    "datasets[\"data20190828\"] = data20190828\n",
    "datasets[\"data20190828SUSNormalized\"] = data20190828SUSNormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectDataset(datasetName):\n",
    "    #_dataName = \"data20190603\"\n",
    "    _dataName = datasetName\n",
    "    assert (_dataName in datasets), (\"Not found in datasets: '\" + _dataName + \"'\")\n",
    "    inputData=datasets[_dataName]\n",
    "\n",
    "    _dataNameSUSNormalized = _dataName + suffixSUSNormalized\n",
    "    assert (_dataName in datasets), (\"Not found in datasets: '\" + _dataNameSUSNormalized + \"'\")\n",
    "    inputDataSUSNormalized=datasets[_dataNameSUSNormalized]\n",
    "    \n",
    "    return _dataName, inputData, _dataNameSUSNormalized, inputDataSUSNormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digital5StepDescriptions = range(minLikertValue, maxLikertValue+1)\n",
    "# mixed5StepDecriptions = ['Strongly agree', '2', '3', '4', 'Strongly disagree']\n",
    "# likert5StepDescriptions = ['Strongly agree', 'Slightly agree', 'Neutral', 'Slightly disagree', 'Strongly disagree']\n",
    "likert5StepDescriptions = ['Strongly agree', 'Agree', 'Neutral', 'Disagree', 'Strongly disagree']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
