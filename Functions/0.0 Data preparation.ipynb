{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n",
    "Imports libraries\n",
    "\n",
    "Loads data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "print(\"0.0 data preparation\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.transforms as tr\n",
    "import seaborn as sns\n",
    "import re\n",
    "import json\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "\n",
    "from random import randint\n",
    "from ipywidgets import FloatProgress,IntProgress,IntText,Text,interact,interactive,IntSlider,FloatSlider\n",
    "from IPython.display import display\n",
    "from itertools import chain\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### common variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryCreateFolder(path, displayMessage = False):\n",
    "    try:  \n",
    "        os.mkdir(path)\n",
    "    except OSError:  \n",
    "        if displayMessage:\n",
    "            print (\"Creation of the directory %s failed\" % path)\n",
    "    else:  \n",
    "        if displayMessage:\n",
    "            print (\"Successfully created the directory %s \" % path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the name of the directory to be created\n",
    "graphsSavePathStem = \"../Graphs\"\n",
    "tryCreateFolder(graphsSavePathStem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixSUSNormalized = \"SUSNormalized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolderPath = \"../Data/\"\n",
    "csvSuffix = '.csv'\n",
    "\n",
    "# Miranda House data\n",
    "unanonymizedDataFilesNamesStemMirandaHouse = \"2019-06-03_event_raw_unanonymized\"\n",
    "dataFilesNamesStemMirandaHouse = \"2019-06-03_event_raw\"\n",
    "unanonymizedRaw20190603PathMirandaHouse = dataFolderPath + unanonymizedDataFilesNamesStemMirandaHouse + csvSuffix\n",
    "raw20190603PathMirandaHouse = dataFolderPath + dataFilesNamesStemMirandaHouse + csvSuffix\n",
    "\n",
    "# Cit√© des Sciences data\n",
    "unanonymizedDataFilesNamesStemCiteDesSciences = \"2019-07-03_event_raw_unanonymized\"\n",
    "dataFilesNamesStemCiteDesSciences = \"2019-07-03_event_raw\"\n",
    "unanonymizedRaw20190703PathCiteDesSciences = dataFolderPath + unanonymizedDataFilesNamesStemCiteDesSciences + csvSuffix\n",
    "raw20190703PathCiteDesSciences = dataFolderPath + dataFilesNamesStemCiteDesSciences + csvSuffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionCount = 12\n",
    "firstLikertQuestionIndex = 0\n",
    "lastLikertQuestionIndex = 11\n",
    "firstSUSQuestionIndex = 0\n",
    "lastSUSQuestionIndex = 10\n",
    "questionArrayInt = [i+1 for i in range(questionCount)]\n",
    "questionArrayStr = sorted([\"Q\" + \"{0:0=2d}\".format(i) for i in questionArrayInt])\n",
    "#questionArrayStr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data anonymization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns anonymized data: replaces Name by identifier and removes the Email column\n",
    "# reads from the unanomizedresult to the anonymizedPath\n",
    "def preprocessAnonymize(unanonymizedPath, anonymizedPath):\n",
    "    unanonymizedData = pd.read_csv(unanonymizedPath,dtype=str)\n",
    "\n",
    "    unanonymizedData = unanonymizedData.drop(axis=1, columns=['Email'])\n",
    "\n",
    "    nameSet = set(unanonymizedData['Name'])\n",
    "    nameSeries = pd.Series(list(nameSet))\n",
    "    for answerIndex in unanonymizedData.index:\n",
    "        name = unanonymizedData.loc[answerIndex, 'Name']\n",
    "        unanonymizedData.loc[answerIndex, 'Name'] = nameSeries.index[nameSeries == name][0]\n",
    "\n",
    "    print(\"writing to \" + anonymizedPath)\n",
    "    unanonymizedData.to_csv(anonymizedPath, encoding='utf-8')\n",
    "    \n",
    "    return unanonymizedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    raw20190603 = preprocessAnonymize(unanonymizedRaw20190603PathMirandaHouse, raw20190603PathMirandaHouse)\n",
    "if False:\n",
    "    raw20190703 = preprocessAnonymize(unanonymizedRaw20190703PathCiteDesSciences, raw20190703PathCiteDesSciences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miranda House\n",
    "try:\n",
    "    raw20190603  = pd.read_csv(raw20190603PathMirandaHouse,dtype=str)\n",
    "except:\n",
    "    print(\"Miranda House data read failed: processing raw data...\")\n",
    "    raw20190603 = preprocessAnonymize(unanonymizedRaw20190603PathMirandaHouse, raw20190603PathMirandaHouse)\n",
    "    raw20190603 = pd.read_csv(raw20190603PathMirandaHouse,dtype=str)\n",
    "finally:\n",
    "    raw20190603 = raw20190603.drop(axis=1, columns=raw20190603.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cite des Sciences\n",
    "try:\n",
    "    raw20190703  = pd.read_csv(raw20190703PathCiteDesSciences,dtype=str)\n",
    "except:\n",
    "    print(\"Cite des Sciences data read failed: processing raw data...\")\n",
    "    raw20190703 = preprocessAnonymize(unanonymizedRaw20190703PathCiteDesSciences, raw20190703PathCiteDesSciences)\n",
    "    raw20190703 = pd.read_csv(raw20190703PathCiteDesSciences,dtype=str)\n",
    "finally:\n",
    "    raw20190703 = raw20190703.drop(axis=1, columns=raw20190703.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert ((raw20190603.columns == raw20190703.columns).all()), \\\n",
    "(\"column mismatch: data from different experiments must have the same columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## additional treatment: column renaming\n",
    "The \"Name\" columns becomes the \"ID\" column due to anonymization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestampQuestion = raw20190603.columns[0]\n",
    "idQuestion = \"ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = raw20190603.columns.values\n",
    "columns[1] = idQuestion\n",
    "\n",
    "raw20190603.columns = columns\n",
    "raw20190703.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## additional treatment: column name extraction\n",
    "Game question\n",
    "short, indexed, Likert, SUS questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameQuestion = raw20190603.columns[2]\n",
    "gameQuestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortQuestions = pd.Series(index=questionArrayStr, data=raw20190603.columns[3:])\n",
    "shortQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexedQuestions = pd.Series(index=range(1,13), data=raw20190603.columns[3:])\n",
    "indexedQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexedLikertQuestions = indexedQuestions[firstLikertQuestionIndex:lastLikertQuestionIndex]\n",
    "indexedLikertQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveLikertQuestions = indexedLikertQuestions.copy()\n",
    "positiveLikertQuestions = positiveLikertQuestions[positiveLikertQuestions.index % 2 == 1]\n",
    "negativeLikertQuestions = indexedLikertQuestions.copy()\n",
    "negativeLikertQuestions = negativeLikertQuestions[negativeLikertQuestions.index % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortLikertQuestions = shortQuestions[firstLikertQuestionIndex:lastLikertQuestionIndex]\n",
    "shortLikertQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexedSUSQuestions = indexedQuestions[firstSUSQuestionIndex:lastSUSQuestionIndex]\n",
    "indexedSUSQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveSUSQuestions = indexedSUSQuestions.copy()\n",
    "positiveSUSQuestions = positiveSUSQuestions[positiveSUSQuestions.index % 2 == 1]\n",
    "negativeSUSQuestions = indexedSUSQuestions.copy()\n",
    "negativeSUSQuestions = negativeSUSQuestions[negativeSUSQuestions.index % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shortSUSQuestions = shortQuestions[firstSUSQuestionIndex:lastSUSQuestionIndex]\n",
    "shortSUSQuestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-word question descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw20190603.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortDescQuestions = pd.Series(index=raw20190603.columns[3:], data=[\n",
    "     \"frequency\",\t\t\t\t#01. I think that I would like to play this game frequently.',\n",
    "     \"complexity\",\t\t\t\t#02. I found the game unnecessarily complex.',\n",
    "     \"ease\",\t\t\t\t\t#03. I thought the game was easy to play.',\n",
    "     \"need for support\",\t\t#04. I think that I would need the support of a technical person to be able to play this game.',    \n",
    "     \"integration\",\t\t\t\t#05. I found the various functions in this game were well integrated.',\n",
    "     \"consistency\",\t\t\t\t#06. I thought there was too much inconsistency in this game.',\n",
    "     \"others' learning\",\t\t#07. I would imagine that most people would learn to play this game very quickly.',\n",
    "     \"convenience\",\t\t\t\t#08. I found the game very cumbersome to play.',\n",
    "\t \"confidence\",\t\t\t\t#09. I felt very confident using the game.',\n",
    "\t \"my learning\",\t\t\t\t#10. I needed to learn a lot of things before I could get going with this game.',\n",
    "\t \"recommendation\",\t\t\t#11. I would recommend this game to a friend.',\n",
    "\t \"remarks\",\t\t\t\t\t#12. Write here your remarks about the game: which feature was missing, what failed or glitched, what was great:',\n",
    "\t ])\n",
    "shortDescQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortDescQuestions = pd.Series(index=raw20190603.columns[3:], data=[\n",
    "     \"replay appeal\",\t\t\t#01. I think that I would like to play this game frequently.',\n",
    "     \"simplicity\",\t\t\t\t#02. I found the game unnecessarily complex.',\n",
    "     \"ease\",\t\t\t\t\t#03. I thought the game was easy to play.',\n",
    "     \"autonomy\",\t\t        #04. I think that I would need the support of a technical person to be able to play this game.',    \n",
    "     \"integration\",\t\t\t\t#05. I found the various functions in this game were well integrated.',\n",
    "     \"consistency\",\t\t\t\t#06. I thought there was too much inconsistency in this game.',\n",
    "     \"learnable by others\",\t\t#07. I would imagine that most people would learn to play this game very quickly.',\n",
    "     \"convenience\",\t\t\t\t#08. I found the game very cumbersome to play.', maniability\n",
    "\t \"confidence\",\t\t\t\t#09. I felt very confident using the game.',\n",
    "\t \"learnable by self\",\t    #10. I needed to learn a lot of things before I could get going with this game.',\n",
    "\t \"recommendation\",\t\t\t#11. I would recommend this game to a friend.',\n",
    "\t \"remarks\",\t\t\t\t\t#12. Write here your remarks about the game: which feature was missing, what failed or glitched, what was great:',\n",
    "\t ])\n",
    "shortDescQuestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## game names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = raw20190603[gameQuestion].unique()\n",
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameDrBugTitle = 'Dr Bug: Microbe Mayhem'\n",
    "gameSuperbugsTitle = 'Superbugs: the Game'\n",
    "gameFungalTitle = 'Fungal Invaders'\n",
    "\n",
    "assert (set(games)==set((gameDrBugTitle, gameSuperbugsTitle, gameFungalTitle))), (\"Wrong list of games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identityGameNames = pd.Series(index=[gameDrBugTitle, gameSuperbugsTitle, gameFungalTitle],\n",
    "                           data=[gameDrBugTitle, gameSuperbugsTitle, gameFungalTitle])\n",
    "shortGameNames = pd.Series(index=identityGameNames.index,\n",
    "                           data=['Dr Bug', 'Superbugs', 'Fungal Invaders'])\n",
    "shortGameNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getShortGameTitle(longGameName):\n",
    "    return shortGameNames.get(longGameName, \"unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## advanced treatment: data refinement\n",
    "Scores are stored as strings and must be converted to integers and NaNs for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumericalData(anonymizedData):\n",
    "    numericalData = anonymizedData.copy()\n",
    "\n",
    "    for question in indexedLikertQuestions:\n",
    "        for respondent in numericalData.index:\n",
    "            try:\n",
    "                numericalData.loc[respondent, question] = int(numericalData.loc[respondent, question])\n",
    "            except:\n",
    "                numericalData.loc[respondent, question] = np.nan\n",
    "    return numericalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNormalizedNumericalData(numericalData):\n",
    "    # transforms the agreement scores (1-5 Likert scale) into a 0-4 mark with 0 = bad and 4 = great\n",
    "    normalizedNumericalData = numericalData.copy()\n",
    "    for respondant in normalizedNumericalData.index:\n",
    "        for question in indexedLikertQuestions:\n",
    "            answer = normalizedNumericalData.loc[respondant, question]\n",
    "            if pd.notna(answer):\n",
    "                if question in negativeLikertQuestions.values:            \n",
    "                    normalizedNumericalData.loc[respondant, question] = 5-answer\n",
    "                else:\n",
    "                    normalizedNumericalData.loc[respondant, question] = answer-1\n",
    "                    \n",
    "    return normalizedNumericalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miranda House data\n",
    "data20190603 = getNumericalData(raw20190603)\n",
    "data20190603SUSNormalized = getNormalizedNumericalData(data20190603)\n",
    "\n",
    "# Cite des Sciences data\n",
    "data20190703 = getNumericalData(raw20190703)\n",
    "data20190703SUSNormalized = getNormalizedNumericalData(data20190703)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dict()\n",
    "\n",
    "datasets[\"data20190603\"] = data20190603\n",
    "datasets[\"data20190603SUSNormalized\"] = data20190603SUSNormalized\n",
    "datasets[\"data20190703\"] = data20190703\n",
    "datasets[\"data20190703SUSNormalized\"] = data20190703SUSNormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectDataset(datasetName):\n",
    "    #_dataName = \"data20190603\"\n",
    "    _dataName = datasetName\n",
    "    assert (_dataName in datasets), (\"Not found in datasets: '\" + _dataName + \"'\")\n",
    "    inputData=datasets[_dataName]\n",
    "\n",
    "    _dataNameSUSNormalized = _dataName + suffixSUSNormalized\n",
    "    assert (_dataName in datasets), (\"Not found in datasets: '\" + _dataNameSUSNormalized + \"'\")\n",
    "    inputDataSUSNormalized=datasets[_dataNameSUSNormalized]\n",
    "    \n",
    "    return _dataName, inputData, _dataNameSUSNormalized, inputDataSUSNormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digital5StepDescriptions = range(minLikertValue, maxLikertValue+1)\n",
    "# mixed5StepDecriptions = ['Strongly agree', '2', '3', '4', 'Strongly disagree']\n",
    "# likert5StepDescriptions = ['Strongly agree', 'Slightly agree', 'Neutral', 'Slightly disagree', 'Strongly disagree']\n",
    "likert5StepDescriptions = ['Strongly agree', 'Agree', 'Neutral', 'Disagree', 'Strongly disagree']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
